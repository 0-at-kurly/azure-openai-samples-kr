{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI에서 Function Calling 사용 방법\n",
    "이 파일은 현재 GPT 모델의 성능을 확장하기 위하여 Function Calling을 Chat Completion API에 사용하는 방법을 보여줍니다. GPT 모델은 본래 외부 시스템, 데이터베이스 또는 파일과의 실시간 상호 작용을 지원하지 않습니다. 그러나 Function Calling을 사용하면 가능해 집니다. 이 자료는 아래의 URL을 한글로 번역해 놓은 자료입니다.\n",
    "- 원문 URL: https://github.com/Azure-Samples/openai/tree/main/Basic_Samples/Functions\n",
    "\n",
    "## Overview\n",
    "`functions`은 Chat Completion API의 옵션으로 제공하는 파라미터이며, 함수의 명세를 제공하는 데 사용할 수 있습니다. 이를 통해 모델은 사용자가 제공한 함수 명세로부터 함수에 필요한 인수(arguments)를 생성할 수 있습니다.\n",
    "\n",
    "참고: API는 함수 호출을 실행하지 않습니다. 출력 인수를 사용하여 함수 호출을 실행하는 것은 개발자가 만들어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI resource 정보를 설정합니다.\n",
    "openai.api_type     = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_key      = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base     = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version  = os.getenv(\"OPENAI_API_VERSION\")   # API 버전은 \"2023-07-01-preview\" 부터 사용 가능합니다.\n",
    "deployment_id       = os.getenv(\"DEPLOYMENT_NAME\")      # Azure OpenAI 리소스의 배포 이름입니다. gpt-35-turbo (0613) 또는 gpt-4 (0613) 버전 이상부터 지원합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `Function Call` 테스트\n",
    "\n",
    "이 코드는 사용자 쿼리와 functions 매개변수에 정의된 함수 집합을 사용하여 모델을 호출합니다. 그런 다음 모델은 Function 호출 여부를 선택할 수 있습니다. 함수가 호출되면 콘텐츠는 문자열화된 JSON 객체에 넣습니다. 만들어야 하는 Function Call 과 인수(arguments)는 `response['choices'][0]['message']['function_call']`에 위치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_call(messages, function_call = \"auto\"):\n",
    "    # Define the functions to use\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"해당 지역의 현재 날씨를 알려줘.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"지역(도시) 이름, e.g. 서울시 동작구\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"섭씨\", \"화씨\"]},\n",
    "                },\n",
    "                \"required\": [\"location\", \"unit\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Call the model with the user query (messages) and the functions defined in the functions parameter\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id = deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=function_call, \n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 `Function`을 강제로 사용하거나 사용하지 않도록 설정\n",
    "`functions` 매개변수(parameter)의 값을 변경하여 모델이 사용할 function을 결정하도록 허용하거나, 모델이 특정 function을 사용하도록 강제하거나, 모델이 function을 사용하지 않도록 강제할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 호출하려는 function을 자동으로 결정:\n",
      "{\n",
      "  \"id\": \"chatcmpl-7feNh7Nyuak1MgLrYQefSYsqIfFNC\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1690161029,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_annotations\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"function_call\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": \"{\\n  \\\"location\\\": \\\"\\uc11c\\uc6b8\\uc2dc \\ub3d9\\uc791\\uad6c\\\",\\n  \\\"unit\\\": \\\"\\uc12d\\uc528\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 34,\n",
      "    \"prompt_tokens\": 117,\n",
      "    \"total_tokens\": 151\n",
      "  }\n",
      "}\n",
      "모델이 어떤 function도 호출하지 않음:\n",
      "{\n",
      "  \"id\": \"chatcmpl-7feNnR4llEwW0aotgciLJawJjovY4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1690161035,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_annotations\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n  \\\"location\\\": \\\"\\uc11c\\uc6b8 \\ub3d9\\uc791\\uad6c\\\",\\n  \\\"unit\\\": \\\"\\uc12d\\uc528\\\"\\n}\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 26,\n",
      "    \"prompt_tokens\": 118,\n",
      "    \"total_tokens\": 144\n",
      "  }\n",
      "}\n",
      "모델이 강제로 지정한 function을 호출:\n",
      "{\n",
      "  \"id\": \"chatcmpl-7feNu57jFDhm8HjrI15Ynzi6B9i58\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1690161042,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_annotations\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": \"{\\n  \\\"location\\\": \\\"\\uc11c\\uc6b8\\uc2dc \\ub3d9\\uc791\\uad6c\\\",\\n  \\\"unit\\\": \\\"\\uc12d\\uc528\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 27,\n",
      "    \"prompt_tokens\": 124,\n",
      "    \"total_tokens\": 151\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "first_message = [{\"role\": \"user\", \"content\": \"서울 동작구의 날씨는 어때?\"}]\n",
    "# 'auto' : Let the model decide what function to call\n",
    "print(\"모델이 호출하려는 function을 자동으로 결정:\")\n",
    "response = get_function_call(first_message, \"auto\")\n",
    "print (response)\n",
    "# print (json.dumps(response['choices'][0]['message']['function_call'], ensure_ascii=False, indent=4))\n",
    "\n",
    "# 'none' : Don't call any function \n",
    "print(\"모델이 어떤 function도 호출하지 않음:\")\n",
    "response = get_function_call(first_message, \"none\")\n",
    "print (response)\n",
    "\n",
    "# force a specific function call\n",
    "print(\"모델이 강제로 지정한 function을 호출:\")\n",
    "response = get_function_call(first_message, function_call={\"name\": \"get_current_weather\"})\n",
    "print (response)\n",
    "# print (json.dumps(response['choices'][0]['message']['function_call'], ensure_ascii=False, indent=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. functions 정의\n",
    "이제 함수로 작업하는 방법을 알았으므로 코드에서 몇 가지 함수를 정의하여 함수를 사용하는 프로세스를 끝까지 살펴보겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Function #1`: Get current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_time(location):\n",
    "    try:\n",
    "        # Get the timezone for the city\n",
    "        timezone = pytz.timezone(location)\n",
    "\n",
    "        # Get the current time in the timezone\n",
    "        now = datetime.now(timezone)\n",
    "        current_time = now.strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "\n",
    "        return current_time\n",
    "    except:\n",
    "        return \"죄송합니다. 해당 지역의 TimeZone을 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-07-24, 10:10:42'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time(\"Asia/Seoul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Function #2`: Get stock market data\n",
    "이 예제에서는 쉬운 설명을 위해 일부 주식 시장 데이터를 하드 코딩한 csv 파일 형태로 제공하지만, 코드를 편집하여 API를 호출하여 실시간 데이터를 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_stock_market_data(index):\n",
    "    available_indices = [\"S&P 500\", \"NASDAQ Composite\", \"Dow Jones Industrial Average\", \"Financial Times Stock Exchange 100 Index\"]\n",
    "\n",
    "    if index not in available_indices:\n",
    "        return \"Invalid index. Please choose from 'S&P 500', 'NASDAQ Composite', 'Dow Jones Industrial Average', 'Financial Times Stock Exchange 100 Index'.\"\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv('./data/stock_data.csv')\n",
    "    \n",
    "    # Filter data for the given index\n",
    "    data_filtered = data[data['Index'] == index]\n",
    "\n",
    "    # Remove 'Index' column\n",
    "    data_filtered = data_filtered.drop(columns=['Index'])\n",
    "\n",
    "    # Convert the DataFrame into a dictionary\n",
    "    hist_dict = data_filtered.to_dict()\n",
    "\n",
    "    for key, value_dict in hist_dict.items():\n",
    "        hist_dict[key] = {k: v for k, v in value_dict.items()}\n",
    "\n",
    "    return json.dumps(hist_dict, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Date\": {\n",
      "        \"2\": \"2023-07-12\",\n",
      "        \"3\": \"2023-07-13\"\n",
      "    },\n",
      "    \"Open\": {\n",
      "        \"2\": 14000.65,\n",
      "        \"3\": 14100.11\n",
      "    },\n",
      "    \"High\": {\n",
      "        \"2\": 14200.06,\n",
      "        \"3\": 14250.0\n",
      "    },\n",
      "    \"Low\": {\n",
      "        \"2\": 13800.08,\n",
      "        \"3\": 14000.67\n",
      "    },\n",
      "    \"Close\": {\n",
      "        \"2\": 14100.44,\n",
      "        \"3\": 14050.81\n",
      "    },\n",
      "    \"Volume\": {\n",
      "        \"2\": 4000000,\n",
      "        \"3\": 4200000\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(get_stock_market_data(\"NASDAQ Composite\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Function #3`: Calculator\n",
    "계산 기능은 math 라이브러리를 이용하여 정확하게 계산하도록 유도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculator(num1, num2, operator):\n",
    "    if operator == '+':\n",
    "        return str(num1 + num2)\n",
    "    elif operator == '-':\n",
    "        return str(num1 - num2)\n",
    "    elif operator == '*':\n",
    "        return str(num1 * num2)\n",
    "    elif operator == '/':\n",
    "        return str(num1 / num2)\n",
    "    elif operator == '**':\n",
    "        return str(num1 ** num2)\n",
    "    elif operator == 'sqrt':\n",
    "        return str(math.sqrt(num1))\n",
    "    else:\n",
    "        return \"Invalid operator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(calculator(5, 5, '+'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPT를 사용한 `Function` 호출\n",
    "\n",
    "`Function Calling`을 위한 단계: \n",
    "\n",
    "1. 사용자 쿼리와 functions 매개변수(parameter)에 정의된 함수 집합을 사용하여 모델을 호출합니다.\n",
    "2. 모델은 함수 호출을 선택할 수 있습니다. 콘텐츠는 사용자 지정 스키마를 준수하는 문자열화된 JSON 객체가 됩니다(참고: 모델이 잘못된 JSON 또는 환각(hallucination) 매개변수를 생성할 수 있음).\n",
    "3. 코드에서 문자열을 JSON으로 구문 분석합니다. 제공된 인수가 있는 경우 해당 인수로 함수를 호출합니다.\n",
    "4. 함수 응답을 새 메시지로 추가하여 모델을 다시 호출하고 모델이 결과를 사용자에게 다시 요약하도록 합니다.\n",
    "\n",
    "### 3.1 모델이 호출 방법을 알 수 있도록 함수 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"Get the current time in a given location\",\n",
    "            # \"description\": \"이 지역의 현재 시간을 알려줘.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location name. The pytz is used to get the timezone for that location. Location names should be in a format like Asia/Seoul, America/New_York, Asia/Bangkok, Europe/London\",\n",
    "                        # \"description\": \"location 이름. pytz는 해당 위치의 시간대를 가져오는 데 사용됩니다. location 이름은 Asia/Seoul, America/New_York, Asia/Bangkok, Europe/London과 같은 형식이어야 합니다.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_stock_market_data\",\n",
    "            \"description\": \"Get the stock market data for a given index\",\n",
    "            # \"description\": \"주어진 인덱스에 대한 주식 시장 데이터 가져오기\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"index\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"S&P 500\", \"NASDAQ Composite\", \"Dow Jones Industrial Average\", \"Financial Times Stock Exchange 100 Index\"]},\n",
    "                },\n",
    "                \"required\": [\"index\"],\n",
    "            },    \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"A simple calculator used to perform basic arithmetic operations\",\n",
    "            # \"description\": \"기본 산술 연산을 수행하는 데 사용되는 간단한 계산기\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"},\n",
    "                    \"operator\": {\"type\": \"string\", \"enum\": [\"+\", \"-\", \"*\", \"/\", \"**\", \"sqrt\"]},\n",
    "                },\n",
    "                \"required\": [\"num1\", \"num2\", \"operator\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "available_functions = {\n",
    "            \"get_current_time\": get_current_time,\n",
    "            \"get_stock_market_data\": get_stock_market_data,\n",
    "            \"calculator\": calculator,\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 function call을 검증하는 helper 함수 정의\n",
    "모델이 잘못된 function call을 생성할 수 있으므로 function의 유효성을 검사하는 것이 중요합니다. 여기서는 사용 사례에 대해 더 복잡한 유효성 검사를 적용할 수 있지만 함수 호출의 유효성을 검사하는 간단한 helper 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# helper method used to check if the correct arguments are provided to a function\n",
    "def check_args(function, args):\n",
    "    sig = inspect.signature(function)\n",
    "    params = sig.parameters\n",
    "\n",
    "    # Check if there are extra arguments\n",
    "    for name in args:\n",
    "        if name not in params:\n",
    "            return False\n",
    "    # Check if the required arguments are provided \n",
    "    for name, param in params.items():\n",
    "        if param.default is param.empty and name not in args:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, functions, available_functions, deployment_id):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        \n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        fuction_to_call = available_functions[function_name]  \n",
    "        \n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if check_args(fuction_to_call, function_args) is False:\n",
    "            return \"Invalid number of arguments for function: \" + function_name\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in second request:\")\n",
    "        # for message in messages:\n",
    "        #     print(message)\n",
    "        # print()\n",
    "        print(json.dumps(messages, ensure_ascii=False, indent=4))\n",
    "        print()\n",
    "\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"get_current_time\",\n",
      "  \"arguments\": \"{\\n\\\"location\\\": \\\"America/Los_Angeles\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "2023-07-23, 18:10:43\n",
      "\n",
      "Messages in second request:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"시애틀의 현재 시간은?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"name\": \"get_current_time\",\n",
      "        \"content\": \"{\\n\\\"location\\\": \\\"America/Los_Angeles\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"get_current_time\",\n",
      "        \"content\": \"2023-07-23, 18:10:43\"\n",
      "    }\n",
      "]\n",
      "\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"\\ud604\\uc7ac \\uc2dc\\uc560\\ud2c0\\uc758 \\uc2dc\\uac04\\uc740 2023\\ub144 7\\uc6d4 23\\uc77c \\uc624\\ud6c4 6\\uc2dc 10\\ubd84 43\\ucd08\\uc785\\ub2c8\\ub2e4.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"현재 시애틀의 시간은 2023년 7월 23일 오후 6시 10분 43초입니다.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"시애틀의 현재 시간은?\"}]\n",
    "assistant_response = run_conversation(messages, functions, available_functions, deployment_id)\n",
    "print(assistant_response['choices'][0]['message'])\n",
    "json.dumps(assistant_response['choices'][0]['message'][\"content\"], ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 동시에 다수의 functions을 호출\n",
    "여러 function call을 함께 연결하여 원하는 결과를 얻을 수 있습니다. 여러 함수 호출이 가능하도록 위의 `run_conversation()` 함수를 수정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiturn_conversation(messages, functions, available_functions, deployment_id):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    while response[\"choices\"][0][\"finish_reason\"] == 'function_call':\n",
    "        response_message = response[\"choices\"][0][\"message\"]\n",
    "        # print(\"Recommended Function call:\")\n",
    "        # print(response_message.get(\"function_call\"))\n",
    "        # print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        \n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        fuction_to_call = available_functions[function_name]  \n",
    "        \n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if check_args(fuction_to_call, function_args) is False:\n",
    "            return \"Invalid number of arguments for function: \" + function_name\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        \n",
    "        # print(\"Output of function call:\")\n",
    "        # print(function_response)\n",
    "        # print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in next request:\")\n",
    "        # for message in messages:\n",
    "        #     print(message)\n",
    "        print(json.dumps(messages, ensure_ascii=False, indent=4))\n",
    "        print()\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id,\n",
    "            function_call=\"auto\",\n",
    "            functions=functions,\n",
    "            temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages in next request:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"How much did S&P 500 change between July 12 and July 13? Use the calculator.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"name\": \"get_stock_market_data\",\n",
      "        \"content\": \"{\\n  \\\"index\\\": \\\"S&P 500\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"get_stock_market_data\",\n",
      "        \"content\": \"{\\n    \\\"Date\\\": {\\n        \\\"0\\\": \\\"2023-07-12\\\",\\n        \\\"1\\\": \\\"2023-07-13\\\"\\n    },\\n    \\\"Open\\\": {\\n        \\\"0\\\": 4300.25,\\n        \\\"1\\\": 4325.55\\n    },\\n    \\\"High\\\": {\\n        \\\"0\\\": 4350.32,\\n        \\\"1\\\": 4350.0\\n    },\\n    \\\"Low\\\": {\\n        \\\"0\\\": 4200.2,\\n        \\\"1\\\": 4300.98\\n    },\\n    \\\"Close\\\": {\\n        \\\"0\\\": 4325.74,\\n        \\\"1\\\": 4310.33\\n    },\\n    \\\"Volume\\\": {\\n        \\\"0\\\": 3500000,\\n        \\\"1\\\": 3600000\\n    }\\n}\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Messages in next request:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"How much did S&P 500 change between July 12 and July 13? Use the calculator.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"name\": \"get_stock_market_data\",\n",
      "        \"content\": \"{\\n  \\\"index\\\": \\\"S&P 500\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"get_stock_market_data\",\n",
      "        \"content\": \"{\\n    \\\"Date\\\": {\\n        \\\"0\\\": \\\"2023-07-12\\\",\\n        \\\"1\\\": \\\"2023-07-13\\\"\\n    },\\n    \\\"Open\\\": {\\n        \\\"0\\\": 4300.25,\\n        \\\"1\\\": 4325.55\\n    },\\n    \\\"High\\\": {\\n        \\\"0\\\": 4350.32,\\n        \\\"1\\\": 4350.0\\n    },\\n    \\\"Low\\\": {\\n        \\\"0\\\": 4200.2,\\n        \\\"1\\\": 4300.98\\n    },\\n    \\\"Close\\\": {\\n        \\\"0\\\": 4325.74,\\n        \\\"1\\\": 4310.33\\n    },\\n    \\\"Volume\\\": {\\n        \\\"0\\\": 3500000,\\n        \\\"1\\\": 3600000\\n    }\\n}\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"name\": \"calculator\",\n",
      "        \"content\": \"{\\n  \\\"num1\\\": 4310.33,\\n  \\\"num2\\\": 4325.74,\\n  \\\"operator\\\": \\\"-\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"calculator\",\n",
      "        \"content\": \"-15.409999999999854\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Final Response:\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The S&P 500 index changed by -15.41 points between July 12 and July 13.\"\n",
      "}\n",
      "\"The S&P 500 index changed by -15.41 points between July 12 and July 13.\"\n",
      "Conversation complete!\n"
     ]
    }
   ],
   "source": [
    "# Can add system prompting to guide the model to call functions and perform in specific ways\n",
    "next_messages = [{\"role\": \"system\", \"content\": \"Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.\"}]\n",
    "next_messages.append({\"role\": \"user\", \"content\": \"How much did S&P 500 change between July 12 and July 13? Use the calculator.\"})\n",
    "# next_messages = [{\"role\": \"system\", \"content\": \"너는 사용자의 질문에 대한 답을 얻을 수 있도록 도와주는 유용한 어시스턴트입니다. 어시스턴트는 여러 도구에 액세스할 수 있으며 경우에 따라 사용자의 답변을 얻기 위해 여러 도구를 순서대로 호출해야 할 수도 있습니다.\"}]\n",
    "# next_messages.append({\"role\": \"user\", \"content\": \"S&P 500은 7월 12일에서 7월 13일에 얼만큼 변경되었습니까? 계산기를 사용하십시오.\"})\n",
    "\n",
    "assistant_response = run_multiturn_conversation(next_messages, functions, available_functions, deployment_id)\n",
    "print(\"Final Response:\")\n",
    "print(assistant_response[\"choices\"][0][\"message\"])\n",
    "print(json.dumps(assistant_response['choices'][0]['message'][\"content\"], ensure_ascii=False))\n",
    "print(\"Conversation complete!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
